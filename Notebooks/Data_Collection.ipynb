{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ef05501-1649-40e0-b142-63feee462be3",
   "metadata": {},
   "source": [
    "## Get Channel ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ee2d4ef-51f7-4bd6-855a-de17dc740453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8785fe0-3359-4123-8ef5-fe15a62447f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfd7a370-9c94-40be-ab0f-8893a2d0daab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel ID: UCSHZKyawb77ixDdsGog4iWA\n"
     ]
    }
   ],
   "source": [
    "# Create a YouTube API client\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "# Search for the channel by name\n",
    "request = youtube.search().list(\n",
    "    q='Lex Fridman',\n",
    "    type='channel',\n",
    "    part='snippet',\n",
    "    maxResults=1\n",
    ")\n",
    "response = request.execute()\n",
    "\n",
    "# Get the channel ID\n",
    "channel_id = response['items'][0]['snippet']['channelId']\n",
    "print(\"Channel ID:\", channel_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4192c296-1600-461f-a049-20a06edef0c6",
   "metadata": {},
   "source": [
    "## Fetch All Videos From Past 2 Years\n",
    "\n",
    "#### 1.  Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf41ddaf-7ce2-4d3f-8c55-87a640c36c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3632cf26-6b13-4fa3-b3a3-6ebc032526f4",
   "metadata": {},
   "source": [
    "## Define and Create Directory Paths\n",
    "\n",
    "To ensure reproducibility and organized storage, we programmatically create directories if they don't already exist for:\n",
    "\n",
    "- **raw data**\n",
    "- **processed data**\n",
    "- **results**\n",
    "- **documentation**\n",
    "\n",
    "These directories will store intermediate and final outputs for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a416b7de-c3fe-43f8-b09d-4795c6df09b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get working directory\n",
    "current_dir = os.getcwd()\n",
    "#go one directory up to root directory\n",
    "project_root_dir = os.path.dirname(current_dir)\n",
    "#Define path to data files\n",
    "data_dir = os.path.join(project_root_dir, 'data')\n",
    "raw_dir = os.path.join(data_dir, 'raw')\n",
    "processed_dir = os.path.join(data_dir, 'processed')\n",
    "#Define path to results folder\n",
    "results_dir = os.path.join(project_root_dir, 'results')\n",
    "#Define path to results folder\n",
    "docs_dir = os.path.join(project_root_dir, 'docs')\n",
    "\n",
    "#Create directories if they do not exist\n",
    "os.makedirs(raw_dir, exist_ok=True)\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "os.makedirs(docs_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13e6a5b-ecee-40f2-bda1-e9f24a628e5b",
   "metadata": {},
   "source": [
    "#### 2. Set Up Time Range (Last 2 Years) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f61f657-7e3a-492f-a6ff-d5b9da8d5beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Today's date and 2 years back\n",
    "today = datetime.now(timezone.utc).isoformat()\n",
    "two_years_ago = (datetime.now(timezone.utc) - timedelta(days=730)).isoformat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af23f454-b51d-4ce6-9020-ede40ba07b6f",
   "metadata": {},
   "source": [
    "#### 3. Fetch Videos Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b0c0d1f-9910-41fc-90ec-6321d204efa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data = []\n",
    "\n",
    "# Paginate through all videos\n",
    "next_page_token = None\n",
    "\n",
    "while True:\n",
    "    request = youtube.search().list(\n",
    "        part = \"snippet\",\n",
    "        channelId = 'UCSHZKyawb77ixDdsGog4iWA',\n",
    "        maxResults = 50,\n",
    "        publishedAfter = two_years_ago,\n",
    "        publishedBefore = today,\n",
    "        order = \"date\",\n",
    "        type = \"video\",\n",
    "        pageToken = next_page_token\n",
    "    )\n",
    "    response = request.execute()\n",
    "    \n",
    "    for item in response['items']:\n",
    "        video_id = item['id']['videoId']\n",
    "        title = item['snippet']['title']\n",
    "        published = item['snippet']['publishedAt']\n",
    "        \n",
    "        # Get video stats\n",
    "        video_request = youtube.videos().list(\n",
    "            part = \"statistics,snippet\",\n",
    "            id = video_id\n",
    "        )\n",
    "        video_response = video_request.execute()\n",
    "        \n",
    "        for v in video_response['items']:\n",
    "            stats = v['statistics']\n",
    "            snippet = v['snippet']\n",
    "            video_data.append({\n",
    "                \"videoId\": video_id,\n",
    "                \"title\": title,\n",
    "                \"publishedAt\": published,\n",
    "                \"viewCount\": int(stats.get(\"viewCount\", 0)),\n",
    "                \"likeCount\": int(stats.get(\"likeCount\", 0)),\n",
    "                \"commentCount\": int(stats.get(\"commentCount\", 0)),\n",
    "                \"tags\": snippet.get(\"tags\", []),\n",
    "                \"description\": snippet.get(\"description\", \"\")\n",
    "            })\n",
    "\n",
    "    # Check if more pages exist\n",
    "    next_page_token = response.get(\"nextPageToken\")\n",
    "    if not next_page_token:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d254a0-8e74-4b03-95d1-66aec5867c68",
   "metadata": {},
   "source": [
    "#### 4. Save Video Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95020b38-e1f9-455d-8401-c770fa77bbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved video metadata. Total videos: 94\n",
      "\n",
      "video datase saved to: C:\\Users\\user\\Documents\\tekHer\\YouTube-Channel-Insights\\data\\raw\\lex_fridman_videos.csv\n"
     ]
    }
   ],
   "source": [
    "video_df = pd.DataFrame(video_data)\n",
    "video_filename = os.path.join(raw_dir, \"lex_fridman_videos.csv\")\n",
    "video_df.to_csv(video_filename, index=False)\n",
    "print(\"Saved video metadata. Total videos:\", len(video_df))\n",
    "print(f\"\\nvideo datase saved to: {video_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7eb527-5067-462e-bbfe-314ca357d138",
   "metadata": {},
   "source": [
    "##  Fetch Top 50 Comments for Each Video\n",
    "\n",
    "For each video:\n",
    "\n",
    "- Get top 50 comments\n",
    "\n",
    "- Store:\n",
    "\n",
    "- `videoId`\n",
    "\n",
    "- `authorDisplayName`\n",
    "\n",
    "- `textDisplay`\n",
    "\n",
    "- `likeCount`\n",
    "\n",
    "- `publishedAt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e24662f-96e9-4922-9041-fc2c096fbb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "comment_data = []\n",
    "\n",
    "for video_id in video_df['videoId']:\n",
    "    try:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part = \"snippet\",\n",
    "            videoId = video_id,\n",
    "            maxResults = 50,\n",
    "            textFormat = \"plainText\"\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response.get('items', []):\n",
    "            snippet = item['snippet']['topLevelComment']['snippet']\n",
    "            comment_data.append({\n",
    "                \"videoId\": video_id,\n",
    "                \"authorDisplayName\": snippet.get(\"authorDisplayName\", \"\"),\n",
    "                \"textDisplay\": snippet.get(\"textDisplay\", \"\"),\n",
    "                \"likeCount\": snippet.get(\"likeCount\", 0),\n",
    "                \"publishedAt\": snippet.get(\"publishedAt\", \"\")\n",
    "            })\n",
    "\n",
    "        # Delay to avoid hitting rate limits\n",
    "        time.sleep(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching comments for {video_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb6618c-b56c-4229-a652-7c7f117ac6bf",
   "metadata": {},
   "source": [
    "#### Save Comments to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9c6c945-5faf-4fba-bd65-fcb556bab9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved comments. Total: 4684\n",
      "\n",
      "video datase saved to: C:\\Users\\user\\Documents\\tekHer\\YouTube-Channel-Insights\\data\\raw\\lex_fridman_comments.csv\n"
     ]
    }
   ],
   "source": [
    "comments_df = pd.DataFrame(comment_data)\n",
    "comments_filename = os.path.join(raw_dir, \"lex_fridman_comments.csv\")\n",
    "comments_df.to_csv(comments_filename, index=False)\n",
    "print(\"Saved comments. Total:\", len(comments_df))\n",
    "print(f\"\\nvideo datase saved to: {comments_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
